# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D4Qjve4HZSnH8jxB3GUi2MYhckZbN73Z
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import MinMaxScaler
import random

seed_num = 42
np.random.seed(seed_num)
random.seed(seed_num)
tf.random.set_seed(seed_num)

#데이터 가져오기
data = pd.read_csv('samsung.csv')

data.head()



#원본 데이터 출력
plt.plot(data['Adj Close'], label='Adj Close')

plt.show()

# 원본 데이터의 정보 출력

data.describe()

# 각 column에 null인 값이 있는지 확인

data.isnull().sum()

# 각 column에 0이 몇개인지 확인

for col in data.columns:
    missing_rows = data.loc[data[col]==0].shape[0]
    print(col + ': ' + str(missing_rows))

# Volume의 값이 0이면 NaN으로 바꿈

data['Volume'] = data['Volume'].replace(0, np.nan)

# 각 column에 0인 값이 몇 개인지 확인

for col in data.columns:

    missing_rows = data.loc[data[col]==0].shape[0]
    print(col + ': ' + str(missing_rows))

# 각 column에 null인 값이 몇 개인지 확인

data.isnull().sum()

#각 행에 null인 값이 있는지 확인
data.isnull().any()

#Open column에 na값이 있는 행 출력
data.loc[data['Open'].isna()]

# na값이 있는 행 삭제

data = data.dropna()

# 각 column의 null 개수 출력
data.isnull().sum()

# Date column을 제외한 나머지 column들을 정규화

scaler = MinMaxScaler()

scale_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']
scaled = scaler.fit_transform(data[scale_cols])
scaled = pd.DataFrame(scaled, columns=scale_cols)

print(scaled)

# 특징 데이터와 label 데이터를 입력받아 시계열 데이터를 만든다.
# shifting을 하여 window를 생성한다.

def make_sequence(feature, label, window):

    feature_list = []
    label_list = []

    # window 크기만큼의 데이터들을 특징 리스트의 각 항목에 저장하고 마지막의 다음 값을 label 리스트에 저장한다.
    for i in range(len(feature)-window):

        feature_list.append(feature[i:i+window])
        label_list.append(label[i+window])

    return np.array(feature_list), np.array(label_list)

# 주가예측을 위한 특징 데이터로 Adj Close를 사용한다. label 데이터 또한 Adj Close로 사용한다.

feature_cols = [ 'Adj Close' ]
label_cols = [ 'Adj Close' ]

feature_df = pd.DataFrame(scaled, columns=feature_cols)
label_df = pd.DataFrame(scaled, columns=label_cols)

# Pandas의 dataframe에서 numpy로 변환한다.

feature = feature_df.to_numpy()
label = label_df.to_numpy()

# 특징 데이터와 label을 사용하여 시계열 데이터를 생성한다.
window = 40

X, Y = make_sequence(feature, label, window)

# 훈련 데이터와 테스트 데이터를 8:2 비율로 분리한다.

split = int(len(X)*0.8)

x_train = X[0:split]
y_train = Y[0:split]

x_test = X[split:]
y_test = Y[split:]

# 레이어를 선형으로 연결하여 구성하기 위해 Sequential 모델을 생성한다.

model = Sequential()

#활성함수로는 ReLU 대신 tanh를 사용한다.
model.add(LSTM(128, activation='tanh', input_shape=x_train[0].shape))
model.add(Dense(1, activation='linear'))

#손실함수로는 평균제곱오차를, 옵티마이저로는 adam을 사용한다.
model.compile(loss='mse', optimizer='adam', metrics=['mae'])

model.summary()

#특정 조건에 도달하면 종료하기 위해 EarlyStopping을 사용한다.
early_stop = EarlyStopping(monitor='val_loss', patience=5)

model.fit(x_train, y_train, 
          validation_data=(x_test, y_test),
          epochs=100, batch_size=16,
          callbacks=[early_stop])

pred = model.predict(x_test)

plt.figure(figsize=(12, 6))
plt.title('adj Close')
plt.ylabel('adj close')
plt.xlabel('period')
plt.plot(y_test, label='actual value')
plt.plot(pred, label='predicted value')
plt.grid()
plt.legend(loc='best')

plt.show()

# 평균 절대 백분율 오차를 계산한다.

print( np.sum(abs(y_test-pred)/y_test) / len(x_test) )